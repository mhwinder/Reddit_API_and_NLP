{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 3. Web API's and NLP, Reddit Modelling\n",
    "\n",
    "This notebook takes the data which was cleaned and explored in the previous notebook, then models it in various ways."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Several required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the data\n",
    "data = pd.read_csv('./data/reddit_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binarize the target variable\n",
    "data['is_ac'] = (data['subreddit']=='AskCulinary').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>link_flair_text</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>selftext</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>title</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>title_word_count</th>\n",
       "      <th>text_word_count</th>\n",
       "      <th>words</th>\n",
       "      <th>is_ac</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ESK777</td>\n",
       "      <td>Equipment Question</td>\n",
       "      <td>30</td>\n",
       "      <td>I just bought a Le Creuset enameled cast iron ...</td>\n",
       "      <td>AskCulinary</td>\n",
       "      <td>Le Creuset enameled cast iron for bread baking</td>\n",
       "      <td>1606798265</td>\n",
       "      <td>8</td>\n",
       "      <td>68</td>\n",
       "      <td>Le Creuset enameled cast iron for bread baking...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   author     link_flair_text  num_comments  \\\n",
       "0  ESK777  Equipment Question            30   \n",
       "\n",
       "                                            selftext    subreddit  \\\n",
       "0  I just bought a Le Creuset enameled cast iron ...  AskCulinary   \n",
       "\n",
       "                                            title  created_utc  \\\n",
       "0  Le Creuset enameled cast iron for bread baking   1606798265   \n",
       "\n",
       "   title_word_count  text_word_count  \\\n",
       "0                 8               68   \n",
       "\n",
       "                                               words  is_ac  \n",
       "0  Le Creuset enameled cast iron for bread baking...      1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display a single row just to remind us what we are working with.\n",
    "data.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform Data\n",
    "\n",
    "Create a stemmed features column a lemmatized features column and the train test split. This will be further transformed into word vectors, but it is important that the vecotrs are fit based on the training set to prevent data leakage. In the EDA notebook this step wasn't taken and the numbers there reflect the entire dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create features with the porter stemmer library\n",
    "# This one takes a few seconds to run\n",
    "stm = PorterStemmer()\n",
    "data['stem'] = [word_tokenize(doc) for doc in data['words']]\n",
    "for i in range(len(data)):\n",
    "    data['stem'].iloc[i] = [stm.stem(word) for word in data['stem'].iloc[i]].copy()\n",
    "data['stem'] = [' '.join(stm_list) for stm_list in data['stem']] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the lemmatized features column\n",
    "lem = WordNetLemmatizer()\n",
    "data['lem'] = [word_tokenize(doc) for doc in data['words']]\n",
    "for i in range(len(data)):\n",
    "    data['lem'].iloc[i] = [lem.lemmatize(word) for word in data['lem'].iloc[i]].copy()\n",
    "data['lem'] = [' '.join(lem_list) for lem_list in data['lem']] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the features matrix and target series. Then split them.\n",
    "X = data.drop(columns='is_ac')\n",
    "y = data['is_ac']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Accuracy Score\n",
    "This score is the simplest possible case where the prediction is simply the majority class every time. Any model should outperform this score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The baseline accuracy score is 0.5055882950619792\n"
     ]
    }
   ],
   "source": [
    "y_train.value_counts(normalize=True)\n",
    "print(f'The baseline accuracy score is {y_train.value_counts(normalize=True)[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Models\n",
    "The models I create are logistic regrerssion, KNN, and RandomForest, with a few different transformers applied to the text data. A summary of accuracy scores will be produced later in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a list of the token sets to automate the calculations.\n",
    "word_sets = ['words', 'lem', 'stem']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This pipeline is for: Logistic Regression\n",
    "# Pipeline adapted from NLP lab review. Thanks for pointing this out Gabe! \n",
    "log_pipe = Pipeline([\n",
    "    ('cv', CountVectorizer()),\n",
    "    ('tf', TfidfTransformer()),\n",
    "    ('lr', LogisticRegression(solver = 'liblinear'))\n",
    "])\n",
    "\n",
    "log_params = {\n",
    "    'cv__max_features': [100, 500],\n",
    "    'cv__ngram_range' : [(1,1), (1,2)],\n",
    "    'cv__stop_words'  : ['english', None],\n",
    "    'tf__use_idf': [True, False] #if True, acts like TFIDF, if False, acts like CountVectorizer\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for words:   0.7146919235689818\n",
      "Score for lem:   0.7248501919029343\n",
      "Score for stem:   0.7205837563451777\n"
     ]
    }
   ],
   "source": [
    "# Loop through all my token sets doing a gridsearch on each\n",
    "log_models = {}\n",
    "for tokens in word_sets:\n",
    "    \n",
    "    gs = GridSearchCV(estimator = log_pipe,\n",
    "                           param_grid = log_params,\n",
    "                           cv = 5,\n",
    "                           n_jobs = 6)\n",
    "    gs.fit(X_train[tokens],y_train);\n",
    "    \n",
    "    log_models[tokens] = gs\n",
    "    print(f'Score for {tokens}:   {gs.best_score_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This pipeline is for: K Nearest Neighbors Classifier\n",
    "knn_pipe = Pipeline([\n",
    "    ('cv', CountVectorizer()),\n",
    "    ('tf', TfidfTransformer()),\n",
    "    ('knn', KNeighborsClassifier())\n",
    "])\n",
    "\n",
    "knn_params = {\n",
    "    'cv__max_features': [100, 500],\n",
    "    'cv__ngram_range' : [(1,1), (1,2)],\n",
    "    'cv__stop_words'  : ['english', None],\n",
    "    'tf__use_idf': [True, False], #if True, acts like TFIDF, if False, acts like CountVectorizer\n",
    "    'knn__n_neighbors' : [15, 25, 30]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for words:   0.6852302835211093\n",
      "Score for lem:   0.6884806652635055\n",
      "Score for stem:   0.6890916594445132\n"
     ]
    }
   ],
   "source": [
    "# Loop through all my token sets doing a gridsearch on each\n",
    "knn_models = {}\n",
    "for tokens in word_sets:\n",
    "    \n",
    "    gs = GridSearchCV(estimator = knn_pipe,\n",
    "                           param_grid = knn_params,\n",
    "                           cv = 5,\n",
    "                           n_jobs = 6)\n",
    "    gs.fit(X_train[tokens],y_train);\n",
    "    \n",
    "    knn_models[tokens] = gs\n",
    "    print(f'Score for {tokens}:   {gs.best_score_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This pipeline is for: Random Forest Classifier\n",
    "rf_pipe = Pipeline([\n",
    "    ('cv', CountVectorizer()),\n",
    "    ('tf', TfidfTransformer()),\n",
    "    ('rf', RandomForestClassifier())\n",
    "])\n",
    "\n",
    "rf_params = {\n",
    "    'cv__max_features': [100, 500],\n",
    "    'cv__ngram_range' : [(1,1), (1,2)],\n",
    "    'cv__stop_words'  : ['english', None],\n",
    "    'tf__use_idf': [True, False], #if True, acts like TFIDF, if False, acts like CountVectorizer\n",
    "    'rf__max_depth' : [None, 5],\n",
    "    'rf__n_estimators' : [50, 100]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for words:   0.7096087656308034\n",
      "Score for lem:   0.7096102100614915\n",
      "Score for stem:   0.7085939498988898\n"
     ]
    }
   ],
   "source": [
    "# Loop through all my token sets doing a gridsearch on each\n",
    "rf_models = {}\n",
    "for tokens in word_sets:\n",
    "    \n",
    "    gs = GridSearchCV(estimator = rf_pipe,\n",
    "                           param_grid = rf_params,\n",
    "                           cv = 5,\n",
    "                           n_jobs = 6)\n",
    "    gs.fit(X_train[tokens],y_train);\n",
    "    \n",
    "    rf_models[tokens] = gs\n",
    "    print(f'Score for {tokens}:   {gs.best_score_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This pipeline is for: Bagging Classifier\n",
    "bag_pipe = Pipeline([\n",
    "    ('cv', CountVectorizer()),\n",
    "    ('tf', TfidfTransformer()),\n",
    "    ('bag',  BaggingClassifier())\n",
    "])\n",
    "\n",
    "bag_params = {\n",
    "    'cv__max_features': [100, 500],\n",
    "    'cv__ngram_range' : [(1,1), (1,2)],\n",
    "    'cv__stop_words'  : ['english', None],\n",
    "    'tf__use_idf': [True, False], #if True, acts like TFIDF, if False, acts like CountVectorizer\n",
    "    'bag__base_estimator' : [None, LogisticRegression(max_iter=2000)],\n",
    "    'bag__n_estimators' : [20]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for words:   0.7167229994634972\n",
      "Score for lem:   0.7207868020304569\n",
      "Score for stem:   0.7185504106310099\n"
     ]
    }
   ],
   "source": [
    "# Loop through all my token sets doing a gridsearch on each\n",
    "bag_models = {}\n",
    "for tokens in word_sets:\n",
    "    \n",
    "    gs = GridSearchCV(estimator = bag_pipe,\n",
    "                           param_grid = bag_params,\n",
    "                           cv = 5,\n",
    "                           n_jobs = 6)\n",
    "    gs.fit(X_train[tokens],y_train);\n",
    "    \n",
    "    bag_models[tokens] = gs\n",
    "    print(f'Score for {tokens}:   {gs.best_score_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This pipeline is for: LinearSVC\n",
    "svc_pipe = Pipeline([\n",
    "    ('cv', CountVectorizer()),\n",
    "    ('tf', TfidfTransformer()),\n",
    "    ('svc',  SVC())\n",
    "])\n",
    "\n",
    "svc_params = {\n",
    "    'cv__max_features': [500],\n",
    "    'cv__ngram_range' : [(1,2)],\n",
    "    'cv__stop_words'  : ['english', None],\n",
    "    'tf__use_idf': [True, False], #if True, acts like TFIDF, if False, acts like CountVectorizer\n",
    "    'svc__C' : np.logspace(-3,1,3),\n",
    "    'svc__kernel' : ['linear','rbf','polynomial','sigmoid']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for words:   0.7075791341669763\n",
      "Score for lem:   0.7104244562750195\n",
      "Score for stem:   0.7130690025174363\n"
     ]
    }
   ],
   "source": [
    "# Loop through all my token sets doing a gridsearch on each\n",
    "svc_models = {}\n",
    "for tokens in word_sets:\n",
    "    \n",
    "    gs = GridSearchCV(estimator = svc_pipe,\n",
    "                           param_grid = svc_params,\n",
    "                           cv = 5,\n",
    "                           n_jobs = 6)\n",
    "    gs.fit(X_train[tokens],y_train);\n",
    "    \n",
    "    svc_models[tokens] = gs\n",
    "    print(f'Score for {tokens}:   {gs.best_score_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine Specificity and Sensitivity\n",
    "\n",
    "Here I will check the sensitivity and specificity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions with the best performing Model\n",
    "prediction = log_models['lem'].predict(X_test['lem'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[405 223]\n",
      " [133 470]]\n"
     ]
    }
   ],
   "source": [
    "# Create a confusion matrix.\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, prediction).ravel()\n",
    "\n",
    "print(confusion_matrix(y_test, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7794361525704809"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate Sensitivity\n",
    "recall_score(y_test, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6449044585987261"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate Specificity\n",
    "specificity = tn / (tn + fp)\n",
    "specificity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I see that the false positives and false negatives are relatively similar. If there was an imbalance that might have been a sign that the data had some sort of additional relationship."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
